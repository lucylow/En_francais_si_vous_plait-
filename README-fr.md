# En franÃ§ais si vous plait? ğŸ‡¨ğŸ‡¦

** Ceci est une soumission de projet d'apprentissage automatique pour le [Global PyTorch Summer Hackathon! # PTSH19] (https://pytorch.devpost.com/) **. For the English readme documentation, [click here!] (Https://github.com/lucylow/en_francais_si_vous_plait-/blob/master/README.md)

<div>
  
  [![Status](https://img.shields.io/badge/status-active-success.svg)]()
  [![GitHub Issues](https://img.shields.io/github/issues/lucylow/en_francais_si_vous_plait.svg)](https://github.com/lucylow/en_francais_si_vous_plait/issues)
  [![GitHub Pull Requests](https://img.shields.io/github/issues-pr/lucylow/en_francais_si_vous_plait.svg)](https://github.com/lucylow/en_francais_si_vous_plait/pulls)
  [![License](https://img.shields.io/bower/l/bootstrap)]()


---

## Motivation

* Mise en Å“uvre de la boÃ®te Ã  outils ** de Fairseq, Machine Learning Sequence Modeling, dans PyTorch **
* ModÃ¨le de transformateur de traduction en langage machine de [* L'attention est tout ce dont vous avez besoin *] (https://arxiv.org/abs/1706.03762)
* Applications mÃ©tier pour connaÃ®tre le ton des communications du client et rÃ©pondre avec un ton appropriÃ©

Â Â Â Â 
---

## Outils techniques

* [** Pytorch **] (https://pytorch.org)
Â Â * Plateforme de recherche en apprentissage en profondeur offrant une flexibilitÃ© et une vitesse maximales ainsi que des tenseurs basÃ©s sur le processeur graphique accÃ©lÃ©rant le calcul
Â Â 
* [** Fairseq de Facebook Research **]] (https://ai.facebook.com/tools/fairseq/)
Â Â * BoÃ®te Ã  outils de modÃ©lisation de sÃ©quence Ã©crite en PyTorch
Â Â * Former des modÃ¨les personnalisÃ©s pour ** traduction neuronale (NMT) ** - traduction, synthÃ¨se, modÃ©lisation de langage et autres tÃ¢ches de gÃ©nÃ©ration de texte
Â 

---

## ModÃ©lisation sÃ©quence par sÃ©quence du transformateur convolutionnel

* Mesurer les traductions de vitesse
Â Â * Enregistrez le temps de traduction une fois que le systÃ¨me d'apprentissage machine affiche une phrase pour quantifier les rÃ©sultats
Â Â * "** CNN le surpasse de 1,5 BLEU pour la tÃ¢che franÃ§ais-anglais du WMT 2014 **, une mÃ©trique largement utilisÃ©e pour juger de l'exactitude de la traduction automatique."
Â Â 
* Gating pour contrÃ´ler le flux d'unitÃ©s cachÃ©es

* ** Attention multi-hop **
Â Â * Le codeur CNN crÃ©e un vecteur pour chaque mot Ã  traduire et le dÃ©codeur CNN traduit les mots pendant que les calculs PyTorch sont effectuÃ©s simultanÃ©ment
Â Â * ** Le rÃ©seau a deux couches de dÃ©codeur et une attention particuliÃ¨re est accordÃ©e Ã  chaque couche. ** Voir l'image ci-dessous.

Â Â Â ! [alt text bonjour] (https://github.com/lucylow/En_francais_si_vous_plait-/blob/master/screenshots/translation_illustration.gif)

Â Â Â * Image de ** Calculs tensoriels ** Ã  sauts multiples ** oÃ¹ les lignes vertes reprÃ©sentent l'attention portÃ©e Ã  chaque mot franÃ§ais. [Source d'image] (https://engineering.fb.com/ml-applications/a-novel-approach-to-neural-machine-translation) *


---
Â 
## Jeu de donnÃ©es de traduction franÃ§ais-anglais

* Traduction automatique statistique [WMT 2014 franÃ§ais-anglais] (http://statmt.org/wmt14/translation-task.html#Download) avec ** phrases d'une taille de corpus de 2,3 Go et 40,8 millions **
* Le jeu de donnÃ©es comprend:
Â Â * Commoncrawl
Â Â * Europarl-v7
Â Â * Giga
Â Â * Nouvelles-commentaires
Â Â * Undoc
* PrÃ©-traitement du corpus de texte WMT2014

`` `terminal
donnÃ©es cd /
bash prepare-iwslt14.sh

TEXT = data / iwslt14.tokenized.fr-fr

# Binarize data
$ fairseq preprocess -sourcelang fr -targetlang en \
Â Â Â Â -trainpref $ TEXT / train -validpref $ TEXT / valide -testpref $ TEXT / test \
Â Â Â Â -thresholdsrc 3 -thresholdtgt 3 -destdir data-bin / iwslt14.tokenized.fr-en
Â Â Â Â travailleurs 60
`` `

---

## Formation technique sur le modÃ¨le franÃ§ais-anglais

** Former le nouveau modÃ¨le CNN avec le train * -fairseq ***

`` `python
$ mkdir -p trainings / fconv

$ fairseq train -sourcelang fr -targetlang en -datadir data-bin / iwslt14.tokenized.fr-en \
Â Â -model fconv -nenclayer 4 -nlayer 3 -dropout 0.2 -optim nag -lr 0.25 -clip 0.1 \
Â Â -momentum 0,99 -timeavg -bptt 0
Â Â -savedir formations / fconv
`` `

** La gÃ©nÃ©ration de modÃ¨le avec * -fairseq gÃ©nÃ¨re ***

`` `python
$ DATA = data-bin / iwslt14.tokenized.fr-en

$ fairseq generate-lines -sourcedict $ DATA / dict.fr.th7 -targetdict $ DATA / dict.en.th7 \
Â Â -path trainings / fconv / model_best_opt.th7 -beam 10 -nbest
| [cible] Dictionnaire: 24738 types
| Dictionnaire [source]: 35474 types

> Pourquoi est-il rare de dÃ©couvrir de nouvelles espÃ¨ces de mammifÃ¨res marins?

Source: Pourquoi est-il rare de dÃ©couvrir de nouvelles espÃ¨ces de mammifÃ¨res marins?
Original_Sentence: Pourquoi est-il rare de dÃ©couvrir de nouvelles espÃ¨ces de mammifÃ¨res marins?
HypothÃ¨se: -0.23804219067097 Pourquoi est-il rare de dÃ©couvrir de nouvelles espÃ¨ces marines mam @@ mal?
Attention_Maxima: 2 2 3 4 5 6 7 8 9
HypothÃ¨se: -0.23861141502857 Pourquoi est-il rare de dÃ©couvrir de nouvelles espÃ¨ces marines mam @@ mal?
Attention_Maxima: 2 2 3 4 5 7 6 7 9 9
`` `
---

## ModÃ¨les techniques et ensembles de test

* ModÃ¨le entiÃ¨rement prÃ©-entrainÃ©
Â Â * ** wmt14.en-fr.fconv-cuda.tar.bz2: ** ModÃ¨le prÃ©-formÃ© pour le WMT14 anglais-franÃ§ais, y compris les vocabulaires
Â Â 
* Ensembles de test pour le modÃ¨le
Â Â * ** wmt14.en-fr.newstest2014.tar.bz2: ** Ensemble de test newstest2014 pour WMT14 anglais-franÃ§ais
Â Â * ** wmt14.en-fr.ntst1213.tar.bz2: ** ensembles de test newstest2012 et newstest2013 pour WMT14 anglais-franÃ§ais


---

## RÃ©fÃ©rences

* https://ai.facebook.com/tools/fairseq/
* Document technique Fairseq
